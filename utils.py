#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ› ï¸ ì „ì„¤ì  í€¸íŠ¸í”„ë¡œì íŠ¸ UTILS ì‹œìŠ¤í…œ - ì™„ì „í†µí•©íŒ
================================================================

ì½”ì–´ ì‹œìŠ¤í…œì„ ì§€ì›í•˜ëŠ” ì „ì„¤ê¸‰ ìœ í‹¸ë¦¬í‹° ëª¨ìŒ
- ğŸ“Š ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ë„êµ¬
- ğŸ”„ ë°ì´í„° ì²˜ë¦¬ ë° ë³€í™˜
- ğŸ“ˆ ì°¨íŠ¸ ë° ì‹œê°í™”
- ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë„êµ¬
- ğŸ“± ì•Œë¦¼ ë° ë¡œê¹… ì‹œìŠ¤í…œ
- ğŸ” ë°±í…ŒìŠ¤íŒ… ì—”ì§„
- ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ í—¬í¼
- ğŸŒ API í†µì‹  ë„êµ¬

Author: ì „ì„¤ì í€¸íŠ¸íŒ€ | Version: UTILS v1.0
"""

import asyncio
import logging
import os
import sys
import json
import time
import warnings
import math
import hashlib
import pickle
import gzip
import csv
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from collections import defaultdict, deque
from functools import wraps, lru_cache
from contextlib import contextmanager
import threading
import queue
import sqlite3
import tempfile
import shutil

# ìˆ˜ì¹˜ ê³„ì‚°
import numpy as np
import pandas as pd
from scipy import stats
from scipy.optimize import minimize
import talib

# ë°ì´í„° ì²˜ë¦¬
import requests
import aiohttp
import yaml
from dotenv import load_dotenv

# ì‹œê°í™”
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# ì™¸ë¶€ API (ì„ íƒì )
try:
    import yfinance as yf
    YF_AVAILABLE = True
except ImportError:
    YF_AVAILABLE = False

try:
    import pyupbit
    UPBIT_AVAILABLE = True
except ImportError:
    UPBIT_AVAILABLE = False

try:
    from ib_insync import *
    IBKR_AVAILABLE = True
except ImportError:
    IBKR_AVAILABLE = False

warnings.filterwarnings('ignore')
load_dotenv()

# ========================================================================================
# ğŸ¨ ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì •
# ========================================================================================

# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['Malgun Gothic', 'AppleGothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# Seaborn ìŠ¤íƒ€ì¼
sns.set_style("darkgrid")
sns.set_palette("husl")

# Plotly ê¸°ë³¸ í…Œë§ˆ
PLOTLY_THEME = "plotly_dark"

# ========================================================================================
# ğŸ“Š ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ë„êµ¬
# ========================================================================================

class TechnicalAnalyzer:
    """ì „ì„¤ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ë„êµ¬"""
    
    @staticmethod
    def calculate_all_indicators(df: pd.DataFrame, 
                               high_col: str = 'High',
                               low_col: str = 'Low', 
                               close_col: str = 'Close',
                               volume_col: str = 'Volume') -> pd.DataFrame:
        """ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œë¥¼ í•œë²ˆì— ê³„ì‚°"""
        result = df.copy()
        
        # ê°€ê²© ë°ì´í„° ì¶”ì¶œ
        high = df[high_col].values
        low = df[low_col].values  
        close = df[close_col].values
        volume = df[volume_col].values if volume_col in df.columns else None
        
        try:
            # ì´ë™í‰ê· ì„ 
            result['SMA_5'] = talib.SMA(close, timeperiod=5)
            result['SMA_10'] = talib.SMA(close, timeperiod=10)
            result['SMA_20'] = talib.SMA(close, timeperiod=20)
            result['SMA_50'] = talib.SMA(close, timeperiod=50)
            result['SMA_200'] = talib.SMA(close, timeperiod=200)
            
            result['EMA_12'] = talib.EMA(close, timeperiod=12)
            result['EMA_26'] = talib.EMA(close, timeperiod=26)
            
            # ë³¼ë¦°ì € ë°´ë“œ
            bb_upper, bb_middle, bb_lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)
            result['BB_Upper'] = bb_upper
            result['BB_Middle'] = bb_middle
            result['BB_Lower'] = bb_lower
            result['BB_Width'] = (bb_upper - bb_lower) / bb_middle * 100
            result['BB_Position'] = (close - bb_lower) / (bb_upper - bb_lower) * 100
            
            # RSI
            result['RSI_14'] = talib.RSI(close, timeperiod=14)
            result['RSI_7'] = talib.RSI(close, timeperiod=7)
            
            # MACD
            macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
            result['MACD'] = macd
            result['MACD_Signal'] = macdsignal
            result['MACD_Hist'] = macdhist
            
            # ìŠ¤í† ìºìŠ¤í‹±
            slowk, slowd = talib.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowd_period=3)
            result['Stoch_K'] = slowk
            result['Stoch_D'] = slowd
            
            # Williams %R
            result['Williams_R'] = talib.WILLR(high, low, close, timeperiod=14)
            
            # CCI
            result['CCI'] = talib.CCI(high, low, close, timeperiod=14)
            
            # ATR (ë³€ë™ì„±)
            result['ATR'] = talib.ATR(high, low, close, timeperiod=14)
            result['ATR_Percent'] = result['ATR'] / close * 100
            
            # ADX (ì¶”ì„¸ê°•ë„)
            result['ADX'] = talib.ADX(high, low, close, timeperiod=14)
            result['PLUS_DI'] = talib.PLUS_DI(high, low, close, timeperiod=14)
            result['MINUS_DI'] = talib.MINUS_DI(high, low, close, timeperiod=14)
            
            # íŒ¨ëŸ¬ë³¼ë¦­ SAR
            result['SAR'] = talib.SAR(high, low, acceleration=0.02, maximum=0.2)
            
            # ì¼ëª©ê· í˜•í‘œ
            result['Ichimoku_Tenkan'] = TechnicalAnalyzer._ichimoku_tenkan(high, low)
            result['Ichimoku_Kijun'] = TechnicalAnalyzer._ichimoku_kijun(high, low)
            
            # ê±°ë˜ëŸ‰ ì§€í‘œ (ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if volume is not None:
                result['OBV'] = talib.OBV(close, volume)
                result['Volume_SMA'] = talib.SMA(volume, timeperiod=20)
                result['Volume_Ratio'] = volume / result['Volume_SMA']
                
                # VWAP (Volume Weighted Average Price)
                result['VWAP'] = TechnicalAnalyzer._calculate_vwap(df, high_col, low_col, close_col, volume_col)
            
            # ìº”ë“¤íŒ¨í„´ ì¸ì‹
            result['Doji'] = talib.CDLDOJI(df['Open'].values if 'Open' in df.columns else close, 
                                          high, low, close)
            result['Hammer'] = talib.CDLHAMMER(df['Open'].values if 'Open' in df.columns else close,
                                               high, low, close)
            result['Engulfing'] = talib.CDLENGULFING(df['Open'].values if 'Open' in df.columns else close,
                                                     high, low, close)
            
            # ì»¤ìŠ¤í…€ ì§€í‘œ
            result['Price_Change'] = close / np.roll(close, 1) - 1
            result['Volatility_20'] = result['Price_Change'].rolling(20).std() * np.sqrt(252) * 100
            result['Momentum_10'] = (close / np.roll(close, 10) - 1) * 100
            
            logging.info("âœ… ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
            
        except Exception as e:
            logging.error(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return result
    
    @staticmethod
    def _ichimoku_tenkan(high: np.ndarray, low: np.ndarray, period: int = 9) -> np.ndarray:
        """ì¼ëª©ê· í˜•í‘œ ì „í™˜ì„ """
        tenkan = np.full(len(high), np.nan)
        for i in range(period-1, len(high)):
            period_high = np.max(high[i-period+1:i+1])
            period_low = np.min(low[i-period+1:i+1])
            tenkan[i] = (period_high + period_low) / 2
        return tenkan
    
    @staticmethod  
    def _ichimoku_kijun(high: np.ndarray, low: np.ndarray, period: int = 26) -> np.ndarray:
        """ì¼ëª©ê· í˜•í‘œ ê¸°ì¤€ì„ """
        kijun = np.full(len(high), np.nan)
        for i in range(period-1, len(high)):
            period_high = np.max(high[i-period+1:i+1])
            period_low = np.min(low[i-period+1:i+1])
            kijun[i] = (period_high + period_low) / 2
        return kijun
    
    @staticmethod
    def _calculate_vwap(df: pd.DataFrame, high_col: str, low_col: str, 
                       close_col: str, volume_col: str) -> pd.Series:
        """VWAP ê³„ì‚°"""
        typical_price = (df[high_col] + df[low_col] + df[close_col]) / 3
        vwap = (typical_price * df[volume_col]).cumsum() / df[volume_col].cumsum()
        return vwap
    
    @staticmethod
    def generate_signals(df: pd.DataFrame) -> pd.DataFrame:
        """ì¢…í•© ë§¤ë§¤ì‹ í˜¸ ìƒì„±"""
        signals = df.copy()
        
        # ì‹œê·¸ë„ ì´ˆê¸°í™”
        signals['Signal_Score'] = 0.0
        signals['Buy_Signal'] = False
        signals['Sell_Signal'] = False
        
        try:
            # RSI ì‹œê·¸ë„
            signals.loc[signals['RSI_14'] < 30, 'Signal_Score'] += 1
            signals.loc[signals['RSI_14'] > 70, 'Signal_Score'] -= 1
            
            # MACD ì‹œê·¸ë„
            signals.loc[signals['MACD'] > signals['MACD_Signal'], 'Signal_Score'] += 0.5
            signals.loc[signals['MACD'] < signals['MACD_Signal'], 'Signal_Score'] -= 0.5
            
            # ë³¼ë¦°ì €ë°´ë“œ ì‹œê·¸ë„
            signals.loc[signals['BB_Position'] < 20, 'Signal_Score'] += 0.5
            signals.loc[signals['BB_Position'] > 80, 'Signal_Score'] -= 0.5
            
            # ì´ë™í‰ê·  ì‹œê·¸ë„
            signals.loc[signals['Close'] > signals['SMA_20'], 'Signal_Score'] += 0.3
            signals.loc[signals['Close'] < signals['SMA_20'], 'Signal_Score'] -= 0.3
            
            # ìµœì¢… ì‹œê·¸ë„
            signals['Buy_Signal'] = signals['Signal_Score'] >= 1.5
            signals['Sell_Signal'] = signals['Signal_Score'] <= -1.5
            
        except Exception as e:
            logging.error(f"ì‹œê·¸ë„ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return signals

class PatternRecognizer:
    """ì°¨íŠ¸ íŒ¨í„´ ì¸ì‹ê¸°"""
    
    @staticmethod
    def detect_support_resistance(df: pd.DataFrame, window: int = 10) -> Dict:
        """ì§€ì§€/ì €í•­ì„  íƒì§€"""
        high = df['High'].values if 'High' in df.columns else df['Close'].values
        low = df['Low'].values if 'Low' in df.columns else df['Close'].values
        
        # ì§€ì§€ì„  (ì €ì )
        support_levels = []
        for i in range(window, len(low) - window):
            if low[i] == min(low[i-window:i+window+1]):
                support_levels.append((i, low[i]))
        
        # ì €í•­ì„  (ê³ ì )
        resistance_levels = []
        for i in range(window, len(high) - window):
            if high[i] == max(high[i-window:i+window+1]):
                resistance_levels.append((i, high[i]))
        
        return {
            'support': support_levels,
            'resistance': resistance_levels
        }
    
    @staticmethod
    def detect_triangle_pattern(df: pd.DataFrame) -> Dict:
        """ì‚¼ê°í˜• íŒ¨í„´ íƒì§€"""
        support_resistance = PatternRecognizer.detect_support_resistance(df)
        
        # ê°„ë‹¨í•œ ì‚¼ê°í˜• íŒ¨í„´ ë¡œì§
        pattern_detected = False
        pattern_type = "none"
        
        if len(support_resistance['support']) >= 2 and len(support_resistance['resistance']) >= 2:
            # ìƒìŠ¹ì‚¼ê°í˜•, í•˜ë½ì‚¼ê°í˜•, ëŒ€ì¹­ì‚¼ê°í˜• íŒë³„ ë¡œì§
            pattern_detected = True
            pattern_type = "symmetric_triangle"  # ê°„ì†Œí™”
        
        return {
            'detected': pattern_detected,
            'type': pattern_type,
            'support_resistance': support_resistance
        }

# ========================================================================================
# ğŸ”„ ë°ì´í„° ì²˜ë¦¬ ë° ë³€í™˜
# ========================================================================================

class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def clean_ohlcv_data(df: pd.DataFrame) -> pd.DataFrame:
        """OHLCV ë°ì´í„° ì •ë¦¬"""
        cleaned = df.copy()
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        cleaned = cleaned.dropna()
        
        # ê°€ê²© ë°ì´í„° ê²€ì¦
        price_cols = ['Open', 'High', 'Low', 'Close']
        available_cols = [col for col in price_cols if col in cleaned.columns]
        
        for col in available_cols:
            # ìŒìˆ˜ ê°€ê²© ì œê±°
            cleaned = cleaned[cleaned[col] > 0]
            
            # ì´ìƒì¹˜ ì œê±° (3ì‹œê·¸ë§ˆ ë£°)
            mean = cleaned[col].mean()
            std = cleaned[col].std()
            cleaned = cleaned[abs(cleaned[col] - mean) <= 3 * std]
        
        # High >= Low ê²€ì¦
        if 'High' in cleaned.columns and 'Low' in cleaned.columns:
            cleaned = cleaned[cleaned['High'] >= cleaned['Low']]
        
        # ê±°ë˜ëŸ‰ ê²€ì¦
        if 'Volume' in cleaned.columns:
            cleaned = cleaned[cleaned['Volume'] >= 0]
        
        logging.info(f"ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {len(df)} -> {len(cleaned)} í–‰")
        return cleaned
    
    @staticmethod
    def resample_data(df: pd.DataFrame, freq: str) -> pd.DataFrame:
        """ë°ì´í„° ë¦¬ìƒ˜í”Œë§"""
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)
        
        resampled = df.resample(freq).agg({
            'Open': 'first',
            'High': 'max', 
            'Low': 'min',
            'Close': 'last',
            'Volume': 'sum'
        }).dropna()
        
        return resampled
    
    @staticmethod
    def calculate_returns(df: pd.DataFrame, price_col: str = 'Close') -> pd.DataFrame:
        """ìˆ˜ìµë¥  ê³„ì‚°"""
        result = df.copy()
        
        # ë‹¨ìˆœ ìˆ˜ìµë¥ 
        result['Return'] = df[price_col].pct_change()
        
        # ë¡œê·¸ ìˆ˜ìµë¥ 
        result['Log_Return'] = np.log(df[price_col] / df[price_col].shift(1))
        
        # ëˆ„ì  ìˆ˜ìµë¥ 
        result['Cumulative_Return'] = (1 + result['Return']).cumprod() - 1
        
        # ë³€ë™ì„±
        result['Volatility'] = result['Return'].rolling(20).std() * np.sqrt(252)
        
        # ìƒ¤í”„ ë¹„ìœ¨ (20ì¼ ì´ë™)
        excess_return = result['Return'] - 0.02/252  # ë¬´ìœ„í—˜ìˆ˜ìµë¥  2%
        result['Sharpe_Ratio'] = excess_return.rolling(20).mean() / result['Return'].rolling(20).std() * np.sqrt(252)
        
        return result
    
    @staticmethod
    def normalize_data(df: pd.DataFrame, method: str = 'minmax') -> pd.DataFrame:
        """ë°ì´í„° ì •ê·œí™”"""
        result = df.copy()
        numeric_cols = result.select_dtypes(include=[np.number]).columns
        
        if method == 'minmax':
            for col in numeric_cols:
                min_val = result[col].min()
                max_val = result[col].max()
                result[col] = (result[col] - min_val) / (max_val - min_val)
        
        elif method == 'zscore':
            for col in numeric_cols:
                result[col] = (result[col] - result[col].mean()) / result[col].std()
        
        elif method == 'robust':
            for col in numeric_cols:
                median = result[col].median()
                mad = np.median(np.abs(result[col] - median))
                result[col] = (result[col] - median) / mad
        
        return result

class DataCache:
    """ë°ì´í„° ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, cache_dir: str = "cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_path(self, key: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        hash_key = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hash_key}.pkl.gz"
    
    def get(self, key: str, max_age_hours: int = 24) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        cache_path = self.get_cache_path(key)
        
        if not cache_path.exists():
            return None
        
        # ìºì‹œ ë§Œë£Œ í™•ì¸
        cache_time = datetime.fromtimestamp(cache_path.stat().st_mtime)
        if datetime.now() - cache_time > timedelta(hours=max_age_hours):
            cache_path.unlink()
            return None
        
        try:
            with gzip.open(cache_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            logging.error(f"ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def set(self, key: str, data: Any) -> bool:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        cache_path = self.get_cache_path(key)
        
        try:
            with gzip.open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            return True
        except Exception as e:
            logging.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def clear(self) -> int:
        """ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬"""
        count = 0
        for cache_file in self.cache_dir.glob("*.pkl.gz"):
            try:
                cache_file.unlink()
                count += 1
            except:
                pass
        return count

# ========================================================================================
# ğŸ“ˆ ì°¨íŠ¸ ë° ì‹œê°í™”
# ========================================================================================

class ChartGenerator:
    """ì°¨íŠ¸ ìƒì„±ê¸°"""
    
    @staticmethod
    def create_candlestick_chart(df: pd.DataFrame, 
                               title: str = "ì£¼ê°€ ì°¨íŠ¸",
                               show_volume: bool = True,
                               show_indicators: bool = True) -> go.Figure:
        """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„±"""
        
        # ì„œë¸Œí”Œë¡¯ ì„¤ì •
        if show_volume:
            fig = make_subplots(
                rows=3, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.05,
                row_heights=[0.6, 0.2, 0.2],
                subplot_titles=(title, "ê±°ë˜ëŸ‰", "ì§€í‘œ")
            )
        else:
            fig = make_subplots(
                rows=2, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.05,
                row_heights=[0.8, 0.2],
                subplot_titles=(title, "ì§€í‘œ")
            )
        
        # ìº”ë“¤ìŠ¤í‹±
        fig.add_trace(
            go.Candlestick(
                x=df.index,
                open=df['Open'],
                high=df['High'],
                low=df['Low'],
                close=df['Close'],
                name="OHLC"
            ),
            row=1, col=1
        )
        
        # ì´ë™í‰ê· ì„ 
        if show_indicators and 'SMA_20' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['SMA_20'],
                    mode='lines',
                    name='MA20',
                    line=dict(color='orange', width=1)
                ),
                row=1, col=1
            )
        
        if show_indicators and 'SMA_50' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['SMA_50'],
                    mode='lines',
                    name='MA50',
                    line=dict(color='blue', width=1)
                ),
                row=1, col=1
            )
        
        # ë³¼ë¦°ì € ë°´ë“œ
        if show_indicators and all(col in df.columns for col in ['BB_Upper', 'BB_Lower']):
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['BB_Upper'],
                    mode='lines',
                    name='BBìƒë‹¨',
                    line=dict(color='gray', width=1, dash='dash'),
                    opacity=0.5
                ),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['BB_Lower'],
                    mode='lines',
                    name='BBí•˜ë‹¨',
                    line=dict(color='gray', width=1, dash='dash'),
                    fill='tonexty',
                    opacity=0.1
                ),
                row=1, col=1
            )
        
        # ê±°ë˜ëŸ‰
        if show_volume and 'Volume' in df.columns:
            colors = ['red' if close < open else 'green' 
                     for close, open in zip(df['Close'], df['Open'])]
            
            fig.add_trace(
                go.Bar(
                    x=df.index,
                    y=df['Volume'],
                    name="ê±°ë˜ëŸ‰",
                    marker_color=colors,
                    opacity=0.7
                ),
                row=2, col=1
            )
        
        # RSI
        if show_indicators and 'RSI_14' in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['RSI_14'],
                    mode='lines',
                    name='RSI',
                    line=dict(color='purple', width=2)
                ),
                row=3 if show_volume else 2, col=1
            )
            
            # RSI ê¸°ì¤€ì„ 
            fig.add_hline(y=70, line_dash="dash", line_color="red", 
                         row=3 if show_volume else 2, col=1, opacity=0.5)
            fig.add_hline(y=30, line_dash="dash", line_color="green", 
                         row=3 if show_volume else 2, col=1, opacity=0.5)
        
        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(
            template=PLOTLY_THEME,
            height=800,
            showlegend=True,
            xaxis_rangeslider_visible=False
        )
        
        # Yì¶• ë²”ìœ„ ì„¤ì •
        fig.update_yaxes(title_text="ê°€ê²©", row=1, col=1)
        if show_volume:
            fig.update_yaxes(title_text="ê±°ë˜ëŸ‰", row=2, col=1)
        if show_indicators:
            fig.update_yaxes(title_text="RSI", range=[0, 100], 
                           row=3 if show_volume else 2, col=1)
        
        return fig
    
    @staticmethod
    def create_performance_chart(returns: pd.Series, 
                               benchmark: Optional[pd.Series] = None,
                               title: str = "ì„±ê³¼ ë¶„ì„") -> go.Figure:
        """ì„±ê³¼ ë¶„ì„ ì°¨íŠ¸"""
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("ëˆ„ì ìˆ˜ìµë¥ ", "ì¼ë³„ìˆ˜ìµë¥  ë¶„í¬", "ë“œë¡œìš°ë‹¤ìš´", "ì›”ë³„ ìˆ˜ìµë¥ "),
            specs=[[{"colspan": 2}, None],
                   [{"type": "histogram"}, {"type": "bar"}]]
        )
        
        # ëˆ„ì ìˆ˜ìµë¥ 
        cumulative = (1 + returns).cumprod()
        fig.add_trace(
            go.Scatter(
                x=returns.index,
                y=cumulative,
                mode='lines',
                name='í¬íŠ¸í´ë¦¬ì˜¤',
                line=dict(color='blue', width=2)
            ),
            row=1, col=1
        )
        
        if benchmark is not None:
            benchmark_cumulative = (1 + benchmark).cumprod()
            fig.add_trace(
                go.Scatter(
                    x=benchmark.index,
                    y=benchmark_cumulative,
                    mode='lines',
                    name='ë²¤ì¹˜ë§ˆí¬',
                    line=dict(color='red', width=2)
                ),
                row=1, col=1
            )
        
        # ìˆ˜ìµë¥  ë¶„í¬
        fig.add_trace(
            go.Histogram(
                x=returns * 100,
                nbinsx=50,
                name='ìˆ˜ìµë¥  ë¶„í¬',
                marker_color='lightblue',
                opacity=0.7
            ),
            row=2, col=1
        )
        
        # ë“œë¡œìš°ë‹¤ìš´
        peak = cumulative.cummax()
        drawdown = (cumulative - peak) / peak * 100
        
        fig.add_trace(
            go.Scatter(
                x=returns.index,
                y=drawdown,
                mode='lines',
                name='ë“œë¡œìš°ë‹¤ìš´',
                line=dict(color='red', width=1),
                fill='tonexty'
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            template=PLOTLY_THEME,
            height=600,
            title_text=title
        )
        
        return fig
    
    @staticmethod
    def save_chart(fig: go.Figure, filename: str, 
                  format: str = 'html', width: int = 1200, height: int = 800):
        """ì°¨íŠ¸ ì €ì¥"""
        Path("charts").mkdir(exist_ok=True)
        filepath = Path("charts") / filename
        
        if format == 'html':
            fig.write_html(str(filepath))
        elif format == 'png':
            fig.write_image(str(filepath), width=width, height=height)
        elif format == 'pdf':
            fig.write_image(str(filepath), format='pdf', width=width, height=height)
        
        logging.info(f"ì°¨íŠ¸ ì €ì¥: {filepath}")

# ========================================================================================
# ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë„êµ¬
# ========================================================================================

class RiskManager:
    """ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    @staticmethod
    def calculate_var(returns: pd.Series, confidence: float = 0.05) -> float:
        """VaR (Value at Risk) ê³„ì‚°"""
        return np.percentile(returns, confidence * 100)
    
    @staticmethod
    def calculate_cvar(returns: pd.Series, confidence: float = 0.05) -> float:
        """CVaR (Conditional VaR) ê³„ì‚°"""
        var = RiskManager.calculate_var(returns, confidence)
        return returns[returns <= var].mean()
    
    @staticmethod
    def calculate_maximum_drawdown(returns: pd.Series) -> Dict:
        """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
        cumulative = (1 + returns).cumprod()
        peak = cumulative.cummax()
        drawdown = (cumulative - peak) / peak
        
        max_dd = drawdown.min()
        max_dd_date = drawdown.idxmin()
        
        # íšŒë³µ ê¸°ê°„ ê³„ì‚°
        recovery_date = None
        if max_dd_date in cumulative.index:
            peak_before_dd = peak.loc[max_dd_date]
            recovery_series = cumulative[cumulative.index > max_dd_date]
            recovery_mask = recovery_series >= peak_before_dd
            if recovery_mask.any():
                recovery_date = recovery_series[recovery_mask].index[0]
        
        return {
            'max_drawdown': max_dd,
            'max_drawdown_date': max_dd_date,
            'recovery_date': recovery_date,
            'drawdown_series': drawdown
        }
    
    @staticmethod
    def calculate_sharpe_ratio(returns: pd.Series, risk_free_rate: float = 0.02) -> float:
        """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°"""
        excess_returns = returns - risk_free_rate / 252
        return excess_returns.mean() / returns.std() * np.sqrt(252)
    
    @staticmethod
    def calculate_sortino_ratio(returns: pd.Series, risk_free_rate: float = 0.02) -> float:
        """ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ê³„ì‚°"""
        excess_returns = returns - risk_free_rate / 252
        downside_returns = returns[returns < 0]
        downside_deviation = downside_returns.std()
        
        if downside_deviation == 0:
            return np.inf
        
        return excess_returns.mean() / downside_deviation * np.sqrt(252)
    
    @staticmethod
    def calculate_calmar_ratio(returns: pd.Series) -> float:
        """ì¹¼ë§ˆ ë¹„ìœ¨ ê³„ì‚°"""
        annual_return = (1 + returns).prod() ** (252 / len(returns)) - 1
        max_dd = RiskManager.calculate_maximum_drawdown(returns)['max_drawdown']
        
        if max_dd == 0:
            return np.inf
        
        return annual_return / abs(max_dd)
    
    @staticmethod
    def portfolio_optimization(returns: pd.DataFrame, 
                             method: str = 'mean_variance') -> Dict:
        """í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”"""
        mean_returns = returns.mean() * 252
        cov_matrix = returns.cov() * 252
        
        num_assets = len(mean_returns)
        
        if method == 'mean_variance':
            # ìµœì†Œë¶„ì‚° í¬íŠ¸í´ë¦¬ì˜¤
            def portfolio_variance(weights):
                return np.dot(weights.T, np.dot(cov_matrix, weights))
            
            constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
            bounds = tuple((0, 1) for _ in range(num_assets))
            initial_guess = num_assets * [1. / num_assets]
            
            result = minimize(portfolio_variance, initial_guess, 
                            method='SLSQP', bounds=bounds, constraints=constraints)
            
            optimal_weights = result.x
            
        elif method == 'equal_weight':
            optimal_weights = np.array([1/num_assets] * num_assets)
        
        elif method == 'risk_parity':
            # ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹°
            def risk_budget_objective(weights):
                portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
                marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol
                contrib = np.multiply(marginal_contrib, weights)
                return np.sum((contrib - contrib.mean())**2)
            
            constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
            bounds = tuple((0.01, 0.99) for _ in range(num_assets))
            initial_guess = num_assets * [1. / num_assets]
            
            result = minimize(risk_budget_objective, initial_guess,
                            method='SLSQP', bounds=bounds, constraints=constraints)
            
            optimal_weights = result.x
        
        else:
            optimal_weights = np.array([1/num_assets] * num_assets)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ê³„ì‚°
        portfolio_return = np.sum(mean_returns * optimal_weights)
        portfolio_vol = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))
        sharpe_ratio = portfolio_return / portfolio_vol
        
        return {
            'weights': optimal_weights,
            'expected_return': portfolio_return,
            'volatility': portfolio_vol,
            'sharpe_ratio': sharpe_ratio,
            'assets': returns.columns.tolist()
        }

class PositionSizer:
    """í¬ì§€ì…˜ ì‚¬ì´ì§•"""
    
    @staticmethod
    def kelly_criterion(win_rate: float, avg_win: float, avg_loss: float) -> float:
        """ì¼ˆë¦¬ ê³µì‹"""
        if avg_loss == 0:
            return 0
        
        b = avg_win / avg_loss
        p = win_rate
        q = 1 - win_rate
        
        kelly_fraction = (b * p - q) / b
        return max(0, min(kelly_fraction, 0.25))  # ìµœëŒ€ 25% ì œí•œ
    
    @staticmethod
    def fixed_fractional(account_value: float, risk_per_trade: float, 
                        entry_price: float, stop_loss: float) -> int:
        """ê³ ì • ë¹„ìœ¨ë²•"""
        risk_amount = account_value * risk_per_trade
        risk_per_share = abs(entry_price - stop_loss)
        
        if risk_per_share == 0:
            return 0
        
        position_size = int(risk_amount / risk_per_share)
        return max(0, position_size)
    
    @staticmethod
    def volatility_adjusted(returns: pd.Series, target_volatility: float = 0.15) -> float:
        """ë³€ë™ì„± ì¡°ì • í¬ì§€ì…˜"""
        current_vol = returns.std() * np.sqrt(252)
        
        if current_vol == 0:
            return 0
        
        return target_volatility / current_vol

# ========================================================================================
# ğŸ“± ì•Œë¦¼ ë° ë¡œê¹… ì‹œìŠ¤í…œ
# ========================================================================================

class NotificationManager:
    """ê³ ê¸‰ ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.discord_webhook = os.getenv('DISCORD_WEBHOOK_URL')
        self.email_config = {
            'smtp_server': os.getenv('SMTP_SERVER', 'smtp.gmail.com'),
            'smtp_port': int(os.getenv('SMTP_PORT', '587')),
            'email': os.getenv('EMAIL_ADDRESS'),
            'password': os.getenv('EMAIL_PASSWORD')
        }
    
    async def send_telegram(self, message: str, parse_mode: str = 'Markdown') -> bool:
        """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_token or not self.telegram_chat_id:
            return False
        
        url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
        data = {
            'chat_id': self.telegram_chat_id,
            'text': message,
            'parse_mode': parse_mode
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=data) as response:
                    return response.status == 200
        except Exception as e:
            logging.error(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def send_discord(self, message: str, title: str = "í€¸íŠ¸í”„ë¡œì íŠ¸ ì•Œë¦¼") -> bool:
        """ë””ìŠ¤ì½”ë“œ ì›¹í›… ì „ì†¡"""
        if not self.discord_webhook:
            return False
        
        data = {
            "embeds": [{
                "title": title,
                "description": message,
                "color": 0x00ff00,
                "timestamp": datetime.now().isoformat()
            }]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.discord_webhook, json=data) as response:
                    return response.status == 204
        except Exception as e:
            logging.error(f"ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    def send_email(self, subject: str, message: str, to_email: str = None) -> bool:
        """ì´ë©”ì¼ ì „ì†¡"""
        if not all([self.email_config['email'], self.email_config['password']]):
            return False
        
        try:
            import smtplib
            from email.mime.text import MIMEText
            from email.mime.multipart import MIMEMultipart
            
            msg = MIMEMultipart()
            msg['From'] = self.email_config['email']
            msg['To'] = to_email or self.email_config['email']
            msg['Subject'] = subject
            
            msg.attach(MIMEText(message, 'plain', 'utf-8'))
            
            server = smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port'])
            server.starttls()
            server.login(self.email_config['email'], self.email_config['password'])
            
            text = msg.as_string()
            server.sendmail(self.email_config['email'], to_email or self.email_config['email'], text)
            server.quit()
            
            return True
            
        except Exception as e:
            logging.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def broadcast_alert(self, message: str, channels: List[str] = None) -> Dict:
        """ë©€í‹°ì±„ë„ ì•Œë¦¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if channels is None:
            channels = ['telegram', 'discord']
        
        results = {}
        
        if 'telegram' in channels:
            results['telegram'] = await self.send_telegram(message)
        
        if 'discord' in channels:
            results['discord'] = await self.send_discord(message)
        
        if 'email' in channels:
            results['email'] = self.send_email("í€¸íŠ¸í”„ë¡œì íŠ¸ ì•Œë¦¼", message)
        
        return results

class SmartLogger:
    """ìŠ¤ë§ˆíŠ¸ ë¡œê¹… ì‹œìŠ¤í…œ"""
    
    def __init__(self, name: str = "QuintProject", level: int = logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.log_dir = Path("logs")
        self.log_dir.mkdir(exist_ok=True)
        
        # í•¸ë“¤ëŸ¬ ì„¤ì •
        self._setup_handlers()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_data = defaultdict(list)
    
    def _setup_handlers(self):
        """ë¡œê·¸ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s | %(name)s | %(levelname)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¼ë³„ ë¡œí…Œì´ì…˜)
        from logging.handlers import TimedRotatingFileHandler
        
        file_handler = TimedRotatingFileHandler(
            self.log_dir / "quint.log",
            when='midnight',
            interval=1,
            backupCount=30,
            encoding='utf-8'
        )
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)
        
        # ì˜¤ë¥˜ ì „ìš© í•¸ë“¤ëŸ¬
        error_handler = TimedRotatingFileHandler(
            self.log_dir / "quint_error.log",
            when='midnight',
            interval=1,
            backupCount=30,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(formatter)
        self.logger.addHandler(error_handler)
    
    def performance_log(self, func_name: str, execution_time: float, **kwargs):
        """ì„±ëŠ¥ ë¡œê·¸"""
        self.performance_data[func_name].append({
            'timestamp': datetime.now(),
            'execution_time': execution_time,
            **kwargs
        })
        
        self.logger.info(f"âš¡ {func_name} ì‹¤í–‰ì‹œê°„: {execution_time:.3f}ì´ˆ")
    
    def get_performance_stats(self, func_name: str = None) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        if func_name:
            data = self.performance_data.get(func_name, [])
            if not data:
                return {}
            
            times = [d['execution_time'] for d in data]
            return {
                'function': func_name,
                'call_count': len(times),
                'avg_time': np.mean(times),
                'min_time': np.min(times),
                'max_time': np.max(times),
                'std_time': np.std(times)
            }
        else:
            return {func: self.get_performance_stats(func) 
                   for func in self.performance_data.keys()}

def performance_monitor(func):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        
        logger = SmartLogger()
        logger.performance_log(func.__name__, execution_time)
        
        return result
    
    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        execution_time = time.time() - start_time
        
        logger = SmartLogger()
        logger.performance_log(func.__name__, execution_time)
        
        return result
    
    return async_wrapper if asyncio.iscoroutinefunction(func) else wrapper

# ========================================================================================
# ğŸ” ë°±í…ŒìŠ¤íŒ… ì—”ì§„
# ========================================================================================

class BacktestEngine:
    """ë°±í…ŒìŠ¤íŒ… ì—”ì§„"""
    
    def __init__(self, initial_capital: float = 100000000):
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.positions = {}
        self.trades = []
        self.portfolio_values = []
        self.fees = 0.001  # 0.1% ìˆ˜ìˆ˜ë£Œ
    
    def add_data(self, symbol: str, data: pd.DataFrame):
        """ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€"""
        if not hasattr(self, 'data'):
            self.data = {}
        self.data[symbol] = data.copy()
    
    def buy(self, symbol: str, date: datetime, price: float, 
           quantity: int = None, amount: float = None):
        """ë§¤ìˆ˜ ì£¼ë¬¸"""
        if symbol not in self.data:
            return False
        
        if quantity is None and amount is None:
            return False
        
        if amount is not None:
            # ê¸ˆì•¡ ê¸°ì¤€ ë§¤ìˆ˜
            total_cost = amount * (1 + self.fees)
            if total_cost > self.capital:
                return False
            
            quantity = int(amount / price)
            if quantity <= 0:
                return False
        
        total_cost = quantity * price * (1 + self.fees)
        
        if total_cost > self.capital:
            return False
        
        # í¬ì§€ì…˜ ì—…ë°ì´íŠ¸
        if symbol in self.positions:
            avg_price = (self.positions[symbol]['price'] * self.positions[symbol]['quantity'] + 
                        price * quantity) / (self.positions[symbol]['quantity'] + quantity)
            self.positions[symbol]['quantity'] += quantity
            self.positions[symbol]['price'] = avg_price
        else:
            self.positions[symbol] = {'quantity': quantity, 'price': price}
        
        # ê±°ë˜ ê¸°ë¡
        self.trades.append({
            'date': date,
            'symbol': symbol,
            'action': 'buy',
            'price': price,
            'quantity': quantity,
            'amount': total_cost,
            'fees': quantity * price * self.fees
        })
        
        self.capital -= total_cost
        return True
    
    def sell(self, symbol: str, date: datetime, price: float, 
            quantity: int = None, ratio: float = None):
        """ë§¤ë„ ì£¼ë¬¸"""
        if symbol not in self.positions:
            return False
        
        available_quantity = self.positions[symbol]['quantity']
        
        if quantity is None and ratio is None:
            quantity = available_quantity  # ì „ëŸ‰ ë§¤ë„
        elif ratio is not None:
            quantity = int(available_quantity * ratio)
        
        quantity = min(quantity, available_quantity)
        if quantity <= 0:
            return False
        
        # ë§¤ë„ ê¸ˆì•¡ ê³„ì‚°
        gross_amount = quantity * price
        net_amount = gross_amount * (1 - self.fees)
        
        # ì†ìµ ê³„ì‚°
        cost_basis = quantity * self.positions[symbol]['price']
        pnl = gross_amount - cost_basis
        
        # ê±°ë˜ ê¸°ë¡
        self.trades.append({
            'date': date,
            'symbol': symbol,
            'action': 'sell',
            'price': price,
            'quantity': quantity,
            'amount': net_amount,
            'fees': gross_amount * self.fees,
            'pnl': pnl,
            'pnl_percent': pnl / cost_basis * 100
        })
        
        # í¬ì§€ì…˜ ì—…ë°ì´íŠ¸
        self.positions[symbol]['quantity'] -= quantity
        if self.positions[symbol]['quantity'] == 0:
            del self.positions[symbol]
        
        self.capital += net_amount
        return True
    
    def get_portfolio_value(self, date: datetime, current_prices: Dict[str, float]) -> float:
        """í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚°"""
        portfolio_value = self.capital
        
        for symbol, position in self.positions.items():
            if symbol in current_prices:
                portfolio_value += position['quantity'] * current_prices[symbol]
        
        return portfolio_value
    
    def run_backtest(self, strategy_func: Callable, start_date: datetime = None, 
                    end_date: datetime = None) -> Dict:
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        if not hasattr(self, 'data') or not self.data:
            return {'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        all_dates = set()
        for symbol_data in self.data.values():
            all_dates.update(symbol_data.index)
        
        dates = sorted(all_dates)
        if start_date:
            dates = [d for d in dates if d >= start_date]
        if end_date:
            dates = [d for d in dates if d <= end_date]
        
        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for date in dates:
            # í˜„ì¬ ê°€ê²© ì •ë³´
            current_prices = {}
            for symbol, symbol_data in self.data.items():
                if date in symbol_data.index:
                    current_prices[symbol] = symbol_data.loc[date, 'Close']
            
            # ì „ëµ ì‹¤í–‰
            signals = strategy_func(self, date, current_prices)
            
            # ì‹ í˜¸ ì²˜ë¦¬
            if signals:
                for signal in signals:
                    if signal['action'] == 'buy':
                        self.buy(signal['symbol'], date, signal['price'], 
                               amount=signal.get('amount'))
                    elif signal['action'] == 'sell':
                        self.sell(signal['symbol'], date, signal['price'], 
                                ratio=signal.get('ratio', 1.0))
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê¸°ë¡
            portfolio_value = self.get_portfolio_value(date, current_prices)
            self.portfolio_values.append({
                'date': date,
                'value': portfolio_value,
                'capital': self.capital,
                'positions_value': portfolio_value - self.capital
            })
        
        return self.generate_backtest_report()
    
    def generate_backtest_report(self) -> Dict:
        """ë°±í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.portfolio_values:
            return {'error': 'ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        portfolio_df = pd.DataFrame(self.portfolio_values)
        portfolio_df.set_index('date', inplace=True)
        
        returns = portfolio_df['value'].pct_change().dropna()
        
        # ì„±ê³¼ ì§€í‘œ
        total_return = (portfolio_df['value'].iloc[-1] / self.initial_capital - 1) * 100
        annual_return = (portfolio_df['value'].iloc[-1] / self.initial_capital) ** (252 / len(portfolio_df)) - 1
        volatility = returns.std() * np.sqrt(252) * 100
        sharpe_ratio = RiskManager.calculate_sharpe_ratio(returns)
        max_dd_info = RiskManager.calculate_maximum_drawdown(returns)
        
        # ê±°ë˜ í†µê³„
        trades_df = pd.DataFrame(self.trades)
        if not trades_df.empty:
            profitable_trades = trades_df[trades_df.get('pnl', 0) > 0]
            win_rate = len(profitable_trades) / len(trades_df) * 100 if len(trades_df) > 0 else 0
            avg_win = profitable_trades['pnl'].mean() if len(profitable_trades) > 0 else 0
            avg_loss = trades_df[trades_df.get('pnl', 0) < 0]['pnl'].mean()
            avg_loss = abs(avg_loss) if not pd.isna(avg_loss) else 0
        else:
            win_rate = avg_win = avg_loss = 0
        
        return {
            'start_date': portfolio_df.index[0],
            'end_date': portfolio_df.index[-1],
            'initial_capital': self.initial_capital,
            'final_value': portfolio_df['value'].iloc[-1],
            'total_return': total_return,
            'annual_return': annual_return * 100,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_dd_info['max_drawdown'] * 100,
            'win_rate': win_rate,
            'total_trades': len(self.trades),
            'avg_win': avg_win,
            'avg_loss': avg_loss,
            'portfolio_values': portfolio_df,
            'trades': trades_df,
            'returns': returns
        }

# ========================================================================================
# ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ í—¬í¼
# ========================================================================================

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì"""
    
    def __init__(self, db_path: str = "quint_data.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ê°€ê²© ë°ì´í„° í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS price_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    date DATE NOT NULL,
                    open_price REAL,
                    high_price REAL,
                    low_price REAL,
                    close_price REAL,
                    volume INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, date)
                )
            ''')
            
            # ê±°ë˜ ê¸°ë¡ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    action TEXT NOT NULL,
                    quantity REAL NOT NULL,
                    price REAL NOT NULL,
                    amount REAL NOT NULL,
                    fees REAL DEFAULT 0,
                    pnl REAL DEFAULT 0,
                    date TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ì‹ í˜¸ ê¸°ë¡ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    action TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    price REAL NOT NULL,
                    target_price REAL,
                    stop_loss REAL,
                    reasoning TEXT,
                    metadata TEXT,
                    date TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ëƒ…ìƒ· í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS portfolio_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    total_value REAL NOT NULL,
                    cash REAL NOT NULL,
                    positions_value REAL NOT NULL,
                    pnl REAL NOT NULL,
                    pnl_percent REAL NOT NULL,
                    position_count INTEGER NOT NULL,
                    date TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_price_symbol_date ON price_data(symbol, date)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_trades_symbol ON trades(symbol)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_signals_symbol ON signals(symbol)')
            
            conn.commit()
    
    def save_price_data(self, symbol: str, data: pd.DataFrame) -> int:
        """ê°€ê²© ë°ì´í„° ì €ì¥"""
        saved_count = 0
        
        with sqlite3.connect(self.db_path) as conn:
            for date, row in data.iterrows():
                try:
                    conn.execute('''
                        INSERT OR REPLACE INTO price_data 
                        (symbol, date, open_price, high_price, low_price, close_price, volume)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        symbol, date.date(),
                        row.get('Open'), row.get('High'), row.get('Low'), 
                        row.get('Close'), row.get('Volume')
                    ))
                    saved_count += 1
                except Exception as e:
                    logging.error(f"ê°€ê²© ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ {symbol} {date}: {e}")
            
            conn.commit()
        
        return saved_count
    
    def load_price_data(self, symbol: str, start_date: datetime = None, 
                       end_date: datetime = None) -> pd.DataFrame:
        """ê°€ê²© ë°ì´í„° ë¡œë“œ"""
        query = "SELECT * FROM price_data WHERE symbol = ?"
        params = [symbol]
        
        if start_date:
            query += " AND date >= ?"
            params.append(start_date.date())
        
        if end_date:
            query += " AND date <= ?"
            params.append(end_date.date())
        
        query += " ORDER BY date"
        
        with sqlite3.connect(self.db_path) as conn:
            df = pd.read_sql_query(query, conn, params=params, parse_dates=['date'])
            
            if not df.empty:
                df.set_index('date', inplace=True)
                df.rename(columns={
                    'open_price': 'Open',
                    'high_price': 'High', 
                    'low_price': 'Low',
                    'close_price': 'Close',
                    'volume': 'Volume'
                }, inplace=True)
                
                # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()
        
        return df
    
    def save_signal(self, signal) -> bool:
        """ì‹ í˜¸ ì €ì¥"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO signals 
                    (symbol, strategy, action, confidence, price, target_price, 
                     stop_loss, reasoning, metadata, date)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    signal.symbol, signal.strategy, signal.action, signal.confidence,
                    signal.price, signal.target_price, signal.stop_loss,
                    signal.reasoning, json.dumps(signal.metadata), signal.timestamp
                ))
                conn.commit()
            return True
        except Exception as e:
            logging.error(f"ì‹ í˜¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def get_signals(self, symbol: str = None, strategy: str = None, 
                   days: int = 30) -> pd.DataFrame:
        """ì‹ í˜¸ ì¡°íšŒ"""
        query = "SELECT * FROM signals WHERE date >= ?"
        params = [datetime.now() - timedelta(days=days)]
        
        if symbol:
            query += " AND symbol = ?"
            params.append(symbol)
        
        if strategy:
            query += " AND strategy = ?"
            params.append(strategy)
        
        query += " ORDER BY date DESC"
        
        with sqlite3.connect(self.db_path) as conn:
            return pd.read_sql_query(query, conn, params=params, parse_dates=['date'])
    
    def save_portfolio_snapshot(self, snapshot: Dict) -> bool:
        """í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO portfolio_snapshots 
                    (total_value, cash, positions_value, pnl, pnl_percent, position_count, date)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    snapshot['total_value'], snapshot['cash'], snapshot['positions_value'],
                    snapshot['pnl'], snapshot['pnl_percent'], snapshot['position_count'],
                    datetime.now()
                ))
                conn.commit()
            return True
        except Exception as e:
            logging.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def cleanup_old_data(self, days: int = 365) -> Dict:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        counts = {}
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ê°€ê²© ë°ì´í„° ì‚­ì œ
            cursor.execute("DELETE FROM price_data WHERE date < ?", (cutoff_date.date(),))
            counts['price_data'] = cursor.rowcount
            
            # ì˜¤ë˜ëœ ì‹ í˜¸ ì‚­ì œ
            cursor.execute("DELETE FROM signals WHERE date < ?", (cutoff_date,))
            counts['signals'] = cursor.rowcount
            
            # ì˜¤ë˜ëœ í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ëƒ…ìƒ· ì‚­ì œ
            cursor.execute("DELETE FROM portfolio_snapshots WHERE date < ?", (cutoff_date,))
            counts['snapshots'] = cursor.rowcount
            
            conn.commit()
        
        return counts

# ========================================================================================
# ğŸŒ API í†µì‹  ë„êµ¬
# ========================================================================================

class APIClient:
    """API í´ë¼ì´ì–¸íŠ¸ ìœ í‹¸ë¦¬í‹°"""
    
    def __init__(self, base_url: str = None, api_key: str = None, 
                 rate_limit: float = 1.0, timeout: int = 30):
        self.base_url = base_url
        self.api_key = api_key
        self.rate_limit = rate_limit  # ì´ˆë‹¹ ìš”ì²­ ìˆ˜ ì œí•œ
        self.timeout = timeout
        self.last_request_time = 0
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=self.timeout)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def _rate_limit_wait(self):
        """ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ëŒ€ê¸°"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        min_interval = 1.0 / self.rate_limit
        
        if time_since_last < min_interval:
            await asyncio.sleep(min_interval - time_since_last)
        
        self.last_request_time = time.time()
    
    async def get(self, endpoint: str, params: Dict = None, headers: Dict = None) -> Dict:
        """GET ìš”ì²­"""
        await self._rate_limit_wait()
        
        url = f"{self.base_url}/{endpoint}" if self.base_url else endpoint
        
        if headers is None:
            headers = {}
        
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'
        
        try:
            async with self.session.get(url, params=params, headers=headers) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status}")
        
        except Exception as e:
            logging.error(f"GET ìš”ì²­ ì‹¤íŒ¨ {url}: {e}")
            raise
    
    async def post(self, endpoint: str, data: Dict = None, headers: Dict = None) -> Dict:
        """POST ìš”ì²­"""
        await self._rate_limit_wait()
        
        url = f"{self.base_url}/{endpoint}" if self.base_url else endpoint
        
        if headers is None:
            headers = {}
        
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'
        
        try:
            async with self.session.post(url, json=data, headers=headers) as response:
                if response.status in [200, 201]:
                    return await response.json()
                else:
                    raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status}")
        
        except Exception as e:
            logging.error(f"POST ìš”ì²­ ì‹¤íŒ¨ {url}: {e}")
            raise

class DataFetcher:
    """ë©€í‹°ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.cache = DataCache()
        self.upbit_client = None
        self.yfinance_available = YF_AVAILABLE
    
    async def fetch_stock_data(self, symbol: str, period: str = "1y", 
                              source: str = "yfinance") -> pd.DataFrame:
        """ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
        cache_key = f"stock_{source}_{symbol}_{period}"
        
        # ìºì‹œ í™•ì¸
        cached_data = self.cache.get(cache_key, max_age_hours=4)
        if cached_data is not None:
            return cached_data
        
        try:
            if source == "yfinance" and self.yfinance_available:
                ticker = yf.Ticker(symbol)
                data = ticker.history(period=period)
                
                if not data.empty:
                    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                    data.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                    data = DataProcessor.clean_ohlcv_data(data)
                    
                    # ìºì‹œ ì €ì¥
                    self.cache.set(cache_key, data)
                    
                    return data
            
            elif source == "alpha_vantage":
                # Alpha Vantage API êµ¬í˜„ (API í‚¤ í•„ìš”)
                api_key = os.getenv('ALPHA_VANTAGE_API_KEY')
                if not api_key:
                    raise Exception("Alpha Vantage API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                async with APIClient(
                    base_url="https://www.alphavantage.co",
                    rate_limit=5  # ë¶„ë‹¹ 5íšŒ ì œí•œ
                ) as client:
                    data = await client.get("query", params={
                        'function': 'TIME_SERIES_DAILY',
                        'symbol': symbol,
                        'apikey': api_key,
                        'outputsize': 'full'
                    })
                    
                    # Alpha Vantage ì‘ë‹µ íŒŒì‹±
                    if 'Time Series (Daily)' in data:
                        time_series = data['Time Series (Daily)']
                        df_data = []
                        
                        for date_str, prices in time_series.items():
                            df_data.append({
                                'Date': pd.to_datetime(date_str),
                                'Open': float(prices['1. open']),
                                'High': float(prices['2. high']),
                                'Low': float(prices['3. low']),
                                'Close': float(prices['4. close']),
                                'Volume': int(prices['5. volume'])
                            })
                        
                        df = pd.DataFrame(df_data)
                        df.set_index('Date', inplace=True)
                        df = df.sort_index()
                        
                        # ê¸°ê°„ í•„í„°ë§
                        if period == "1y":
                            df = df.last('365D')
                        elif period == "6mo":
                            df = df.last('180D')
                        elif period == "3mo":
                            df = df.last('90D')
                        
                        self.cache.set(cache_key, df)
                        return df
            
        except Exception as e:
            logging.error(f"ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ {symbol}: {e}")
        
        return pd.DataFrame()
    
    async def fetch_crypto_data(self, symbol: str, interval: str = "day", 
                               count: int = 200) -> pd.DataFrame:
        """ê°€ìƒí™”í ë°ì´í„° ìˆ˜ì§‘"""
        cache_key = f"crypto_upbit_{symbol}_{interval}_{count}"
        
        # ìºì‹œ í™•ì¸
        cached_data = self.cache.get(cache_key, max_age_hours=1)
        if cached_data is not None:
            return cached_data
        
        try:
            if UPBIT_AVAILABLE:
                data = pyupbit.get_ohlcv(symbol, interval=interval, count=count)
                
                if data is not None and not data.empty:
                    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                    data.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                    data = DataProcessor.clean_ohlcv_data(data)
                    
                    # ìºì‹œ ì €ì¥
                    self.cache.set(cache_key, data)
                    
                    return data
            
            else:
                # Binance API ëŒ€ì•ˆ
                async with APIClient(
                    base_url="https://api.binance.com/api/v3",
                    rate_limit=10
                ) as client:
                    # ì‹¬ë³¼ ë³€í™˜ (KRW-BTC -> BTCUSDT)
                    binance_symbol = symbol.replace('KRW-', '') + 'USDT'
                    
                    data = await client.get("klines", params={
                        'symbol': binance_symbol,
                        'interval': '1d' if interval == 'day' else '1h',
                        'limit': count
                    })
                    
                    if data:
                        df_data = []
                        for kline in data:
                            df_data.append({
                                'Date': pd.to_datetime(int(kline[0]), unit='ms'),
                                'Open': float(kline[1]),
                                'High': float(kline[2]),
                                'Low': float(kline[3]),
                                'Close': float(kline[4]),
                                'Volume': float(kline[5])
                            })
                        
                        df = pd.DataFrame(df_data)
                        df.set_index('Date', inplace=True)
                        
                        self.cache.set(cache_key, df)
                        return df
        
        except Exception as e:
            logging.error(f"ê°€ìƒí™”í ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ {symbol}: {e}")
        
        return pd.DataFrame()
    
    async def fetch_economic_data(self, indicator: str) -> pd.DataFrame:
        """ê²½ì œ ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘"""
        cache_key = f"economic_{indicator}"
        
        # ìºì‹œ í™•ì¸
        cached_data = self.cache.get(cache_key, max_age_hours=24)
        if cached_data is not None:
            return cached_data
        
        try:
            # FRED API ì‚¬ìš©
            fred_api_key = os.getenv('FRED_API_KEY')
            if not fred_api_key:
                logging.warning("FRED API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return pd.DataFrame()
            
            async with APIClient(
                base_url="https://api.stlouisfed.org/fred",
                rate_limit=2
            ) as client:
                data = await client.get("series/observations", params={
                    'series_id': indicator,
                    'api_key': fred_api_key,
                    'file_type': 'json',
                    'limit': 1000
                })
                
                if 'observations' in data:
                    df_data = []
                    for obs in data['observations']:
                        if obs['value'] != '.':
                            df_data.append({
                                'Date': pd.to_datetime(obs['date']),
                                'Value': float(obs['value'])
                            })
                    
                    df = pd.DataFrame(df_data)
                    df.set_index('Date', inplace=True)
                    
                    self.cache.set(cache_key, df)
                    return df
        
        except Exception as e:
            logging.error(f"ê²½ì œ ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨ {indicator}: {e}")
        
        return pd.DataFrame()

# ========================================================================================
# ğŸ›ï¸ ì„¤ì • ê´€ë¦¬ì
# ========================================================================================

class ConfigManager:
    """ê³ ê¸‰ ì„¤ì • ê´€ë¦¬ì"""
    
    def __init__(self, config_file: str = "config.yaml"):
        self.config_file = config_file
        self.config = {}
        self.watchers = []
        self.load_config()
    
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if Path(self.config_file).exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = yaml.safe_load(f) or {}
            else:
                self.create_default_config()
            
            self._substitute_env_vars()
            logging.info(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {self.config_file}")
            
        except Exception as e:
            logging.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.create_default_config()
    
    def create_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
        self.config = {
            'system': {
                'name': 'QuintProject',
                'version': '1.0.0',
                'debug': False,
                'log_level': 'INFO'
            },
            'trading': {
                'default_position_size': 0.02,
                'max_positions': 10,
                'stop_loss': 0.08,
                'take_profit': 0.12,
                'fees': 0.001
            },
            'risk_management': {
                'max_daily_loss': 0.02,
                'max_portfolio_risk': 0.15,
                'correlation_threshold': 0.7
            },
            'data_sources': {
                'primary': 'yfinance',
                'cache_hours': 4,
                'retry_attempts': 3
            },
            'notifications': {
                'telegram': {
                    'enabled': True,
                    'token': '${TELEGRAM_BOT_TOKEN}',
                    'chat_id': '${TELEGRAM_CHAT_ID}'
                },
                'email': {
                    'enabled': False,
                    'smtp_server': '${SMTP_SERVER}',
                    'email': '${EMAIL_ADDRESS}',
                    'password': '${EMAIL_PASSWORD}'
                }
            }
        }
        self.save_config()
    
    def save_config(self):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, 
                         allow_unicode=True, indent=2)
        except Exception as e:
            logging.error(f"ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get(self, key_path: str, default=None):
        """ì  í‘œê¸°ë²•ìœ¼ë¡œ ì„¤ì •ê°’ ì¡°íšŒ"""
        keys = key_path.split('.')
        value = self.config
        
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default
        
        return value
    
    def set(self, key_path: str, value):
        """ì  í‘œê¸°ë²•ìœ¼ë¡œ ì„¤ì •ê°’ ë³€ê²½"""
        keys = key_path.split('.')
        config = self.config
        
        for key in keys[:-1]:
            if key not in config:
                config[key] = {}
            config = config[key]
        
        config[keys[-1]] = value
        self.save_config()
        
        # ê´€ì°°ìë“¤ì—ê²Œ ì•Œë¦¼
        for watcher in self.watchers:
            watcher(key_path, value)
    
    def watch(self, callback: Callable):
        """ì„¤ì • ë³€ê²½ ê´€ì°°ì ë“±ë¡"""
        self.watchers.append(callback)
    
    def _substitute_env_vars(self):
        """í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜"""
        def substitute_recursive(obj):
            if isinstance(obj, dict):
                return {k: substitute_recursive(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [substitute_recursive(item) for item in obj]
            elif isinstance(obj, str) and obj.startswith('${') and obj.endswith('}'):
                var_content = obj[2:-1]
                if ':-' in var_content:
                    var_name, default = var_content.split(':-', 1)
                    return os.getenv(var_name, default)
                else:
                    return os.getenv(var_content, obj)
            return obj
        
        self.config = substitute_recursive(self.config)

# ========================================================================================
# ğŸš€ í¼í¬ë¨¼ìŠ¤ ìµœì í™” ë„êµ¬
# ========================================================================================

class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ë„êµ¬"""
    
    @staticmethod
    def parallel_execute(func: Callable, items: List, max_workers: int = 4) -> List:
        """ë³‘ë ¬ ì‹¤í–‰"""
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(func, item) for item in items]
            results = []
            
            for future in futures:
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                except Exception as e:
                    logging.error(f"ë³‘ë ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    results.append(None)
            
            return results
    
    @staticmethod
    async def async_parallel_execute(func: Callable, items: List, 
                                   semaphore_limit: int = 10) -> List:
        """ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰"""
        semaphore = asyncio.Semaphore(semaphore_limit)
        
        async def limited_func(item):
            async with semaphore:
                return await func(item)
        
        tasks = [limited_func(item) for item in items]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    @staticmethod
    def batch_process(data: List, batch_size: int, 
                     processor: Callable) -> List:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        results = []
        
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            try:
                batch_result = processor(batch)
                results.extend(batch_result if isinstance(batch_result, list) else [batch_result])
            except Exception as e:
                logging.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        return results

# ========================================================================================
# ğŸ¯ ì „ëµ ë°±í…ŒìŠ¤íŒ… í—¬í¼
# ========================================================================================

def simple_moving_average_strategy(backtest_engine, date, current_prices):
    """ë‹¨ìˆœ ì´ë™í‰ê·  ì „ëµ ì˜ˆì‹œ"""
    signals = []
    
    for symbol, price in current_prices.items():
        if symbol in backtest_engine.data:
            data = backtest_engine.data[symbol]
            
            # í˜„ì¬ ë‚ ì§œê¹Œì§€ì˜ ë°ì´í„°
            current_data = data[data.index <= date]
            
            if len(current_data) >= 50:
                sma_20 = current_data['Close'].rolling(20).mean().iloc[-1]
                sma_50 = current_data['Close'].rolling(50).mean().iloc[-1]
                
                # ê³¨ë“ í¬ë¡œìŠ¤
                if sma_20 > sma_50 and symbol not in backtest_engine.positions:
                    signals.append({
                        'symbol': symbol,
                        'action': 'buy',
                        'price': price,
                        'amount': backtest_engine.capital * 0.1  # 10% íˆ¬ì
                    })
                
                # ë°ë“œí¬ë¡œìŠ¤
                elif sma_20 < sma_50 and symbol in backtest_engine.positions:
                    signals.append({
                        'symbol': symbol,
                        'action': 'sell',
                        'price': price,
                        'ratio': 1.0  # ì „ëŸ‰ ë§¤ë„
                    })
    
    return signals

def rsi_strategy(backtest_engine, date, current_prices):
    """RSI ì „ëµ ì˜ˆì‹œ"""
    signals = []
    
    for symbol, price in current_prices.items():
        if symbol in backtest_engine.data:
            data = backtest_engine.data[symbol]
            current_data = data[data.index <= date]
            
            if len(current_data) >= 14:
                # RSI ê³„ì‚°
                delta = current_data['Close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs))
                current_rsi = rsi.iloc[-1]
                
                # RSI ê³¼ë§¤ë„ (30 ì´í•˜)
                if current_rsi < 30 and symbol not in backtest_engine.positions:
                    signals.append({
                        'symbol': symbol,
                        'action': 'buy',
                        'price': price,
                        'amount': backtest_engine.capital * 0.05
                    })
                
                # RSI ê³¼ë§¤ìˆ˜ (70 ì´ìƒ)
                elif current_rsi > 70 and symbol in backtest_engine.positions:
                    signals.append({
                        'symbol': symbol,
                        'action': 'sell',
                        'price': price,
                        'ratio': 1.0
                    })
    
    return signals

# ========================================================================================
# ğŸ® ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ========================================================================================

def create_sample_data(symbol: str = "TEST", days: int = 252, 
                      start_price: float = 100.0) -> pd.DataFrame:
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    dates = pd.date_range(start=datetime.now() - timedelta(days=days), 
                         periods=days, freq='D')
    
    # ëœë¤ ì›Œí¬ë¡œ ê°€ê²© ìƒì„±
    np.random.seed(42)
    returns = np.random.normal(0.001, 0.02, days)  # í‰ê·  0.1%, í‘œì¤€í¸ì°¨ 2%
    prices = [start_price]
    
    for ret in returns:
        prices.append(prices[-1] * (1 + ret))
    
    prices = prices[1:]  # ì²« ë²ˆì§¸ ì œê±°
    
    # OHLCV ë°ì´í„° ìƒì„±
    data = []
    for i, (date, price) in enumerate(zip(dates, prices)):
        high = price * (1 + abs(np.random.normal(0, 0.01)))
        low = price * (1 - abs(np.random.normal(0, 0.01)))
        open_price = prices[i-1] if i > 0 else price
        close_price = price
        volume = int(np.random.uniform(100000, 1000000))
        
        data.append({
            'Open': open_price,
            'High': max(high, open_price, close_price),
            'Low': min(low, open_price, close_price),
            'Close': close_price,
            'Volume': volume
        })
    
    df = pd.DataFrame(data, index=dates)
    return df

def format_number(value: float, decimals: int = 2, suffix: str = "") -> str:
    """ìˆ«ì í¬ë§·íŒ…"""
    if abs(value) >= 1_000_000_000:
        return f"{value/1_000_000_000:.{decimals}f}B{suffix}"
    elif abs(value) >= 1_000_000:
        return f"{value/1_000_000:.{decimals}f}M{suffix}"
    elif abs(value) >= 1_000:
        return f"{value/1_000:.{decimals}f}K{suffix}"
    else:
        return f"{value:.{decimals}f}{suffix}"

def format_percentage(value: float, decimals: int = 2) -> str:
    """í¼ì„¼íŠ¸ í¬ë§·íŒ…"""
    sign = "+" if value > 0 else ""
    return f"{sign}{value:.{decimals}f}%"

def format_currency(value: float, currency: str = "KRW") -> str:
    """í†µí™” í¬ë§·íŒ…"""
    if currency == "KRW":
        return f"{value:,.0f}ì›"
    elif currency == "USD":
        return f"${value:,.2f}"
    elif currency == "JPY":
        return f"Â¥{value:,.0f}"
    else:
        return f"{value:,.2f} {currency}"

@contextmanager
def timer(description: str = "ì‘ì—…"):
    """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    start_time = time.time()
    yield
    end_time = time.time()
    logging.info(f"â±ï¸ {description} ì™„ë£Œ: {end_time - start_time:.3f}ì´ˆ")

def validate_dataframe(df: pd.DataFrame, required_columns: List[str]) -> bool:
    """ë°ì´í„°í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬"""
    if df.empty:
        return False
    
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        logging.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        return False
    
    return True

def safe_divide(a: float, b: float, default: float = 0.0) -> float:
    """ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ"""
    try:
        if b == 0:
            return default
        return a / b
    except:
        return default

def retry_on_exception(max_retries: int = 3, delay: float = 1.0):
    """ì˜ˆì™¸ ë°œìƒì‹œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    logging.warning(f"ì¬ì‹œë„ {attempt + 1}/{max_retries}: {e}")
                    time.sleep(delay * (attempt + 1))
            
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    logging.warning(f"ì¬ì‹œë„ {attempt + 1}/{max_retries}: {e}")
                    await asyncio.sleep(delay * (attempt + 1))
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else wrapper
    return decorator

# ========================================================================================
# ğŸ ìµœì¢… ìµìŠ¤í¬íŠ¸
# ========================================================================================

__all__ = [
    # ê¸°ìˆ ì  ë¶„ì„
    'TechnicalAnalyzer',
    'PatternRecognizer',
    
    # ë°ì´í„° ì²˜ë¦¬
    'DataProcessor',
    'DataCache',
    'DataFetcher',
    
    # ì°¨íŠ¸ ë° ì‹œê°í™”
    'ChartGenerator',
    
    # ë¦¬ìŠ¤í¬ ê´€ë¦¬
    'RiskManager',
    'PositionSizer',
    
    # ì•Œë¦¼ ë° ë¡œê¹…
    'NotificationManager',
    'SmartLogger',
    'performance_monitor',
    
    # ë°±í…ŒìŠ¤íŒ…
    'BacktestEngine',
    'simple_moving_average_strategy',
    'rsi_strategy',
    
    # ë°ì´í„°ë² ì´ìŠ¤
    'DatabaseManager',
    
    # API í†µì‹ 
    'APIClient',
    
    # ì„¤ì • ê´€ë¦¬
    'ConfigManager',
    
    # ì„±ëŠ¥ ìµœì í™”
    'PerformanceOptimizer',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    'create_sample_data',
    'format_number',
    'format_percentage', 
    'format_currency',
    'timer',
    'validate_dataframe',
    'safe_divide',
    'retry_on_exception'
]

"""
ğŸ› ï¸ QuintProject Utils ì‚¬ìš© ì˜ˆì‹œ:

# 1. ê¸°ìˆ ì  ë¶„ì„
from utils import TechnicalAnalyzer
df_with_indicators = TechnicalAnalyzer.calculate_all_indicators(df)
signals = TechnicalAnalyzer.generate_signals(df_with_indicators)

# 2. ì°¨íŠ¸ ìƒì„±
from utils import ChartGenerator
fig = ChartGenerator.create_candlestick_chart(df, "AAPL ì°¨íŠ¸")
ChartGenerator.save_chart(fig, "aapl_chart.html")

# 3. ë¦¬ìŠ¤í¬ ê´€ë¦¬
from utils import RiskManager
sharpe = RiskManager.calculate_sharpe_ratio(returns)
max_dd = RiskManager.calculate_maximum_drawdown(returns)

# 4. ë°±í…ŒìŠ¤íŒ…
from utils import BacktestEngine, simple_moving_average_strategy
engine = BacktestEngine(initial_capital=1000000)
engine.add_data("AAPL", aapl_data)
result = await engine.run_backtest(simple_moving_average_strategy)

# 5. ë°ì´í„° ìˆ˜ì§‘
from utils import DataFetcher
fetcher = DataFetcher()
aapl_data = await fetcher.fetch_stock_data("AAPL", period="1y")
btc_data = await fetcher.fetch_crypto_data("KRW-BTC")

# 6. ì•Œë¦¼ ì‹œìŠ¤í…œ
from utils import NotificationManager
notifier = NotificationManager()
await notifier.broadcast_alert("ğŸš¨ ë§¤ìˆ˜ ì‹ í˜¸ ë°œìƒ!", ["telegram", "discord"])

# 7. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
from utils import performance_monitor, timer

@performance_monitor
async def my_strategy():
    # ì „ëµ ë¡œì§
    pass

with timer("ë°ì´í„° ì²˜ë¦¬"):
    processed_data = process_large_dataset(data)

# 8. ë°ì´í„°ë² ì´ìŠ¤
from utils import DatabaseManager
db = DatabaseManager()
db.save_price_data("AAPL", aapl_data)
saved_data = db.load_price_data("AAPL", start_date=datetime(2024, 1, 1))

# 9. í¬ì§€ì…˜ ì‚¬ì´ì§•
from utils import PositionSizer
kelly_size = PositionSizer.kelly_criterion(0.6, 100, 50)  # ìŠ¹ë¥  60%, í‰ê· ìŠ¹:100, í‰ê· íŒ¨:50
position_size = PositionSizer.fixed_fractional(1000000, 0.02, 100, 92)

# 10. í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
from utils import RiskManager
returns_df = pd.DataFrame({'AAPL': aapl_returns, 'GOOGL': googl_returns})
optimal_portfolio = RiskManager.portfolio_optimization(returns_df, method='mean_variance')

# 11. ì„¤ì • ê´€ë¦¬
from utils import ConfigManager
config = ConfigManager()
trading_config = config.get('trading.default_position_size', 0.02)
config.set('risk_management.max_daily_loss', 0.03)

# 12. ìºì‹±
from utils import DataCache
cache = DataCache()
cache.set("market_data_20241207", market_data)
cached_data = cache.get("market_data_20241207", max_age_hours=4)

# 13. ë³‘ë ¬ ì²˜ë¦¬
from utils import PerformanceOptimizer
symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN']
results = await PerformanceOptimizer.async_parallel_execute(
    fetch_stock_data, symbols, semaphore_limit=5
)

# 14. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
from utils import format_number, format_percentage, format_currency
print(format_number(1234567.89))  # "1.23M"
print(format_percentage(0.0547))  # "+5.47%"
print(format_currency(1234567, "USD"))  # "$1,234,567.00"

# 15. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
from utils import create_sample_data
sample_df = create_sample_data("TEST", days=252, start_price=100)

# 16. íŒ¨í„´ ì¸ì‹
from utils import PatternRecognizer
support_resistance = PatternRecognizer.detect_support_resistance(df)
triangle_pattern = PatternRecognizer.detect_triangle_pattern(df)

# 17. ë°ì´í„° ì •ê·œí™”
from utils import DataProcessor
normalized_df = DataProcessor.normalize_data(df, method='minmax')
clean_df = DataProcessor.clean_ohlcv_data(raw_df)
returns_df = DataProcessor.calculate_returns(df)

# 18. API í´ë¼ì´ì–¸íŠ¸
from utils import APIClient
async with APIClient(base_url="https://api.example.com", rate_limit=5) as client:
    data = await client.get("endpoint", params={"symbol": "AAPL"})

# 19. ì¬ì‹œë„ ë°ì½”ë ˆì´í„°
from utils import retry_on_exception

@retry_on_exception(max_retries=3, delay=1.0)
def unreliable_api_call():
    # ë¶ˆì•ˆì •í•œ API í˜¸ì¶œ
    pass

# 20. ìŠ¤ë§ˆíŠ¸ ë¡œê¹…
from utils import SmartLogger
logger = SmartLogger("MyStrategy")
logger.logger.info("ì „ëµ ì‹œì‘")
logger.performance_log("calculate_indicators", 0.234)
stats = logger.get_performance_stats("calculate_indicators")
"""

# ========================================================================================
# ğŸ¯ ì¶”ê°€ ì „ëµ í…œí”Œë¦¿
# ========================================================================================

def bollinger_bands_strategy(backtest_engine, date, current_prices):
    """ë³¼ë¦°ì € ë°´ë“œ ì „ëµ"""
    signals = []
    
    for symbol, price in current_prices.items():
        if symbol in backtest_engine.data:
            data = backtest_engine.data[symbol]
            current_data = data[data.index <= date]
            
            if len(current_data) >= 20:
                # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
                sma = current_data['Close'].rolling(20).mean()
                std = current_data['Close'].rolling(20).std()
                upper_band = sma + (std * 2)
                lower_band = sma - (std * 2)
                
                current_price = current_data['Close'].iloc[-1]
                current_upper = upper_band.iloc[-1]
                current_lower = lower_band.iloc[-1]
                
                # í•˜ë‹¨ ë°´ë“œ í„°ì¹˜ ì‹œ ë§¤ìˆ˜
                if (current_price <= current_lower and 
                    symbol not in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'buy',
                        'price': price,
                        'amount': backtest_engine.capital * 0.1
                    })
                
                # ìƒë‹¨ ë°´ë“œ í„°ì¹˜ ì‹œ ë§¤ë„
                elif (current_price >= current_upper and 
                      symbol in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'sell',
                        'price': price,
                        'ratio': 1.0
                    })
    
    return signals

def macd_strategy(backtest_engine, date, current_prices):
    """MACD ì „ëµ"""
    signals = []
    
    for symbol, price in current_prices.items():
        if symbol in backtest_engine.data:
            data = backtest_engine.data[symbol]
            current_data = data[data.index <= date]
            
            if len(current_data) >= 35:  # 26 + 9
                # MACD ê³„ì‚°
                ema_12 = current_data['Close'].ewm(span=12).mean()
                ema_26 = current_data['Close'].ewm(span=26).mean()
                macd_line = ema_12 - ema_26
                signal_line = macd_line.ewm(span=9).mean()
                
                # ì‹œê·¸ë„
                current_macd = macd_line.iloc[-1]
                current_signal = signal_line.iloc[-1]
                prev_macd = macd_line.iloc[-2] if len(macd_line) > 1 else current_macd
                prev_signal = signal_line.iloc[-2] if len(signal_line) > 1 else current_signal
                
                # ê³¨ë“ í¬ë¡œìŠ¤ (MACDê°€ ì‹œê·¸ë„ì„ ì„ ìƒí–¥ëŒíŒŒ)
                if (prev_macd <= prev_signal and current_macd > current_signal and
                    symbol not in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'buy',
                        'price': price,
                        'amount': backtest_engine.capital * 0.08
                    })
                
                # ë°ë“œí¬ë¡œìŠ¤ (MACDê°€ ì‹œê·¸ë„ì„ ì„ í•˜í–¥ëŒíŒŒ)
                elif (prev_macd >= prev_signal and current_macd < current_signal and
                      symbol in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'sell',
                        'price': price,
                        'ratio': 1.0
                    })
    
    return signals

def momentum_strategy(backtest_engine, date, current_prices):
    """ëª¨ë©˜í…€ ì „ëµ"""
    signals = []
    
    for symbol, price in current_prices.items():
        if symbol in backtest_engine.data:
            data = backtest_engine.data[symbol]
            current_data = data[data.index <= date]
            
            if len(current_data) >= 21:
                # 20ì¼ ëª¨ë©˜í…€
                momentum_20 = (current_data['Close'].iloc[-1] / 
                              current_data['Close'].iloc[-21] - 1) * 100
                
                # ê±°ë˜ëŸ‰ í™•ì¸
                avg_volume = current_data['Volume'].rolling(20).mean().iloc[-1]
                current_volume = current_data['Volume'].iloc[-1]
                volume_ratio = current_volume / avg_volume
                
                # ê°•í•œ ìƒìŠ¹ ëª¨ë©˜í…€ + ê±°ë˜ëŸ‰ ì¦ê°€
                if (momentum_20 > 5 and volume_ratio > 1.5 and 
                    symbol not in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'buy',
                        'price': price,
                        'amount': backtest_engine.capital * 0.12
                    })
                
                # ëª¨ë©˜í…€ ì†Œì‹¤
                elif (momentum_20 < -3 and symbol in backtest_engine.positions):
                    signals.append({
                        'symbol': symbol,
                        'action': 'sell',
                        'price': price,
                        'ratio': 1.0
                    })
    
    return signals

# ========================================================================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ë„êµ¬
# ========================================================================================

class StrategyTester:
    """ì „ëµ í…ŒìŠ¤íŠ¸ ë„êµ¬"""
    
    @staticmethod
    def quick_backtest(strategy_func: Callable, symbols: List[str], 
                      period: str = "1y") -> Dict:
        """ë¹ ë¥¸ ë°±í…ŒìŠ¤íŠ¸"""
        try:
            # ë°ì´í„° ìˆ˜ì§‘
            data_fetcher = DataFetcher()
            backtest_engine = BacktestEngine(initial_capital=10000000)  # 1ì²œë§Œì›
            
            async def run_test():
                for symbol in symbols:
                    data = await data_fetcher.fetch_stock_data(symbol, period)
                    if not data.empty:
                        backtest_engine.add_data(symbol, data)
                
                return await backtest_engine.run_backtest(strategy_func)
            
            # ë™ê¸° ì‹¤í–‰ì„ ìœ„í•œ ë˜í¼
            try:
                loop = asyncio.get_event_loop()
                result = loop.run_until_complete(run_test())
            except RuntimeError:
                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ” ê²½ìš°
                import nest_asyncio
                nest_asyncio.apply()
                loop = asyncio.get_event_loop()
                result = loop.run_until_complete(run_test())
            
            return result
            
        except Exception as e:
            logging.error(f"ë¹ ë¥¸ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    @staticmethod
    def compare_strategies(strategies: Dict[str, Callable], symbols: List[str]) -> pd.DataFrame:
        """ì „ëµ ë¹„êµ"""
        results = []
        
        for strategy_name, strategy_func in strategies.items():
            try:
                result = StrategyTester.quick_backtest(strategy_func, symbols)
                
                if 'error' not in result:
                    results.append({
                        'Strategy': strategy_name,
                        'Total_Return': result.get('total_return', 0),
                        'Annual_Return': result.get('annual_return', 0),
                        'Sharpe_Ratio': result.get('sharpe_ratio', 0),
                        'Max_Drawdown': result.get('max_drawdown', 0),
                        'Win_Rate': result.get('win_rate', 0),
                        'Total_Trades': result.get('total_trades', 0)
                    })
                else:
                    logging.error(f"ì „ëµ {strategy_name} ì‹¤íŒ¨: {result['error']}")
            
            except Exception as e:
                logging.error(f"ì „ëµ {strategy_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        return pd.DataFrame(results)

def validate_strategy(strategy_func: Callable) -> Dict:
    """ì „ëµ ê²€ì¦"""
    validation_results = {
        'is_valid': True,
        'errors': [],
        'warnings': []
    }
    
    try:
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        sample_data = create_sample_data("TEST", days=100)
        backtest_engine = BacktestEngine(initial_capital=1000000)
        backtest_engine.add_data("TEST", sample_data)
        
        # ì²« ë²ˆì§¸ ë‚ ì§œë¡œ í…ŒìŠ¤íŠ¸
        test_date = sample_data.index[50]  # ì¤‘ê°„ ì§€ì 
        current_prices = {"TEST": sample_data.loc[test_date, 'Close']}
        
        signals = strategy_func(backtest_engine, test_date, current_prices)
        
        # ì‹ í˜¸ ê²€ì¦
        if not isinstance(signals, list):
            validation_results['errors'].append("ì „ëµ í•¨ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤")
            validation_results['is_valid'] = False
        
        for signal in signals:
            if not isinstance(signal, dict):
                validation_results['errors'].append("ì‹ í˜¸ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
                validation_results['is_valid'] = False
                continue
            
            required_keys = ['symbol', 'action', 'price']
            missing_keys = set(required_keys) - set(signal.keys())
            if missing_keys:
                validation_results['errors'].append(f"ì‹ í˜¸ì— í•„ìˆ˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_keys}")
                validation_results['is_valid'] = False
            
            if signal.get('action') not in ['buy', 'sell']:
                validation_results['errors'].append("actionì€ 'buy' ë˜ëŠ” 'sell'ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
                validation_results['is_valid'] = False
    
    except Exception as e:
        validation_results['errors'].append(f"ì „ëµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        validation_results['is_valid'] = False
    
    return validation_results

# ========================================================================================
# ğŸ ë©”ì¸ ì‹¤í–‰ë¶€ (í…ŒìŠ¤íŠ¸ìš©)
# ========================================================================================

async def main():
    """Utils ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("ğŸ› ï¸" + "=" * 70)
    print("ğŸ”¥ QuintProject Utils í…ŒìŠ¤íŠ¸")
    print("=" * 72)
    
    try:
        # 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        print("\nğŸ“Š 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±...")
        sample_data = create_sample_data("TEST", days=100, start_price=100)
        print(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(sample_data)}í–‰")
        
        # 2. ê¸°ìˆ ì  ë¶„ì„
        print("\nğŸ“ˆ 2. ê¸°ìˆ ì  ë¶„ì„...")
        with timer("ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"):
            analyzed_data = TechnicalAnalyzer.calculate_all_indicators(sample_data)
        print(f"âœ… ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€: {len(analyzed_data.columns)}ê°œ ì»¬ëŸ¼")
        
        # 3. ì‹œê·¸ë„ ìƒì„±
        print("\nğŸ¯ 3. ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±...")
        signals_data = TechnicalAnalyzer.generate_signals(analyzed_data)
        buy_signals = signals_data['Buy_Signal'].sum()
        sell_signals = signals_data['Sell_Signal'].sum()
        print(f"âœ… ë§¤ìˆ˜ ì‹ í˜¸: {buy_signals}ê°œ, ë§¤ë„ ì‹ í˜¸: {sell_signals}ê°œ")
        
        # 4. ì°¨íŠ¸ ìƒì„±
        print("\nğŸ“Š 4. ì°¨íŠ¸ ìƒì„±...")
        fig = ChartGenerator.create_candlestick_chart(
            analyzed_data.tail(50), 
            title="ìƒ˜í”Œ ë°ì´í„° ì°¨íŠ¸",
            show_volume=True,
            show_indicators=True
        )
        ChartGenerator.save_chart(fig, "sample_chart.html")
        print("âœ… ì°¨íŠ¸ ì €ì¥: charts/sample_chart.html")
        
        # 5. ë°±í…ŒìŠ¤íŒ…
        print("\nğŸ” 5. ë°±í…ŒìŠ¤íŒ…...")
        backtest_engine = BacktestEngine(initial_capital=10000000)
        backtest_engine.add_data("TEST", sample_data)
        
        # ë‹¨ìˆœ ì´ë™í‰ê·  ì „ëµ í…ŒìŠ¤íŠ¸
        with timer("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
            result = await backtest_engine.run_backtest(simple_moving_average_strategy)
        
        if 'error' not in result:
            print(f"âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
            print(f"   ğŸ“ˆ ì´ ìˆ˜ìµë¥ : {result['total_return']:.2f}%")
            print(f"   ğŸ“Š ìƒ¤í”„ ë¹„ìœ¨: {result['sharpe_ratio']:.2f}")
            print(f"   ğŸ“‰ ìµœëŒ€ ë‚™í­: {result['max_drawdown']:.2f}%")
            print(f"   ğŸ¯ ìŠ¹ë¥ : {result['win_rate']:.1f}%")
        else:
            print(f"âŒ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result['error']}")
        
        # 6. ì„±ê³¼ ë¶„ì„
        print("\nğŸ“Š 6. ì„±ê³¼ ë¶„ì„...")
        returns = sample_data['Close'].pct_change().dropna()
        
        sharpe = RiskManager.calculate_sharpe_ratio(returns)
        sortino = RiskManager.calculate_sortino_ratio(returns)
        max_dd_info = RiskManager.calculate_maximum_drawdown(returns)
        
        print(f"âœ… ì„±ê³¼ ì§€í‘œ:")
        print(f"   ğŸ“Š ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.3f}")
        print(f"   ğŸ“Š ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨: {sortino:.3f}")
        print(f"   ğŸ“‰ ìµœëŒ€ ë‚™í­: {max_dd_info['max_drawdown']*100:.2f}%")
        
        # 7. ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        print("\nğŸ’¾ 7. ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸...")
        db = DatabaseManager("test_utils.db")
        saved_count = db.save_price_data("TEST", sample_data)
        loaded_data = db.load_price_data("TEST")
        print(f"âœ… ë°ì´í„° ì €ì¥: {saved_count}í–‰")
        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(loaded_data)}í–‰")
        
        # 8. ìºì‹œ í…ŒìŠ¤íŠ¸
        print("\nğŸ—„ï¸ 8. ìºì‹œ í…ŒìŠ¤íŠ¸...")
        cache = DataCache("test_cache")
        cache.set("test_data", sample_data)
        cached_data = cache.get("test_data")
        print(f"âœ… ìºì‹œ ì €ì¥/ë¡œë“œ: {'ì„±ê³µ' if cached_data is not None else 'ì‹¤íŒ¨'}")
        
        # 9. ì „ëµ ê²€ì¦
        print("\nğŸ§ª 9. ì „ëµ ê²€ì¦...")
        validation = validate_strategy(simple_moving_average_strategy)
        print(f"âœ… ì „ëµ ìœ íš¨ì„±: {'í†µê³¼' if validation['is_valid'] else 'ì‹¤íŒ¨'}")
        if validation['errors']:
            for error in validation['errors']:
                print(f"   âŒ {error}")
        
        # 10. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        print("\nğŸ® 10. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        print(f"âœ… ìˆ«ì í¬ë§·: {format_number(1234567.89)}")
        print(f"âœ… í¼ì„¼íŠ¸ í¬ë§·: {format_percentage(5.47)}")
        print(f"âœ… í†µí™” í¬ë§·: {format_currency(1234567)}")
        
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logging.error(f"Utils í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(message)s'
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

# ========================================================================================
# ğŸ“š ë¬¸ì„œí™” ì •ë³´
# ========================================================================================

"""
ğŸ› ï¸ QuintProject Utils v1.0 - ì™„ì „ ê°€ì´ë“œ
================================================

ì´ ëª¨ë“ˆì€ QuintProject Coreë¥¼ ì§€ì›í•˜ëŠ” ì „ì„¤ê¸‰ ìœ í‹¸ë¦¬í‹° ëª¨ìŒì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
---------
1. ğŸ“Š ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ (50+ ì§€í‘œ)
2. ğŸ“ˆ í”„ë¡œí˜ì…”ë„ ì°¨íŠ¸ ìƒì„± 
3. ğŸ” ë°±í…ŒìŠ¤íŒ… ì—”ì§„
4. ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë„êµ¬
5. ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
6. ğŸ“± ë©€í‹°ì±„ë„ ì•Œë¦¼ ì‹œìŠ¤í…œ
7. ğŸŒ API í†µì‹  ë„êµ¬
8. ğŸš€ ì„±ëŠ¥ ìµœì í™” ë„êµ¬

ì„¤ì¹˜ ìš”êµ¬ì‚¬í•­:
-------------
pip install pandas numpy scipy matplotlib seaborn plotly
pip install yfinance pyupbit talib aiohttp requests pyyaml python-dotenv

ì„ íƒì  ì˜ì¡´ì„±:
-------------
pip install nest-asyncio  # Jupyter í™˜ê²½
pip install ib-insync      # IBKR ì—°ë™

ì‚¬ìš©ë²•:
------
from utils import *

# ê¸°ë³¸ ì‚¬ìš©
data = create_sample_data("TEST", 100)
analyzed = TechnicalAnalyzer.calculate_all_indicators(data)
fig = ChartGenerator.create_candlestick_chart(analyzed)

# ë°±í…ŒìŠ¤íŒ…
engine = BacktestEngine()
engine.add_data("TEST", data)
result = await engine.run_backtest(simple_moving_average_strategy)

# ì•Œë¦¼
notifier = NotificationManager()
await notifier.send_telegram("ë§¤ìˆ˜ ì‹ í˜¸ ë°œìƒ!")

í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
-------------
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
TELEGRAM_CHAT_ID=your_chat_id
DISCORD_WEBHOOK_URL=your_discord_webhook
EMAIL_ADDRESS=your_email
EMAIL_PASSWORD=your_app_password
FRED_API_KEY=your_fred_api_key
ALPHA_VANTAGE_API_KEY=your_av_api_key

ë¼ì´ì„¼ìŠ¤: MIT
ì‘ì„±ì: ì „ì„¤ì í€¸íŠ¸íŒ€
ë²„ì „: 1.0.0
"""
